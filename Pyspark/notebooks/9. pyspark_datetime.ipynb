{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime\n",
    "from pyspark.sql import SparkSession,Window,DataFrame\n",
    "import datetime\n",
    "from pyspark.sql.functions import  col, lit, udf, datediff, lead, explode\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,LongType,ArrayType\n",
    "from typing import List\n",
    "from pyspark.sql.functions import to_date \n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime\n",
    "df = spark.createDataFrame(\n",
    "    [(\"11251991123445\",), (\"11241991123445\",), (\"11301991123445\",)], \n",
    "    ['date_str']\n",
    ")\n",
    "\n",
    "df2 = df.select(\n",
    "    'date_str', \n",
    "    from_unixtime(unix_timestamp('date_str', 'MMddyyyyhhmmss'))[0:10].alias('date')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_str: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|      date_str|      date|\n",
      "+--------------+----------+\n",
      "|11251991123445|1991-11-25|\n",
      "|11241991123445|1991-11-24|\n",
      "|11301991123445|1991-11-30|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- jobStartDate: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------------+------+\n",
      "|jobStartDate|salary|\n",
      "+------------+------+\n",
      "|01-01-2006  |1     |\n",
      "|02-01-2006  |2     |\n",
      "|04-01-2006  |3     |\n",
      "|05-01-2006  |4     |\n",
      "|07-01-2006  |5     |\n",
      "+------------+------+\n",
      "\n",
      "root\n",
      " |-- jobStartDate: date (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------------+------+\n",
      "|jobStartDate|salary|\n",
      "+------------+------+\n",
      "|2006-01-01  |1     |\n",
      "|2006-01-02  |2     |\n",
      "|2006-01-04  |3     |\n",
      "|2006-01-05  |4     |\n",
      "|2006-01-07  |5     |\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"01-01-2006\",1),\n",
    "    (\"02-01-2006\",2),\n",
    "    (\"04-01-2006\",3),\n",
    "    (\"05-01-2006\",4),\n",
    "    (\"07-01-2006\",5),\n",
    "  ]\n",
    "\n",
    "columns = [\"jobStartDate\",\"salary\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "# df2 = df.withColumn(\"jobStartDate\",col(\"jobStartDate\").cast(DateType())) \\\n",
    "#     .withColumn(\"salary\",col(\"salary\").cast(LongType()))\n",
    "\n",
    "# df2.printSchema()\n",
    "# df2.show(truncate=False)\n",
    "\n",
    "df1 = df.select(to_date(df.jobStartDate, 'dd-mm-yyyy').alias('jobStartDate'),\"salary\")\n",
    "df1.printSchema()\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_next_dates(start_date, diff):\n",
    "    return [start_date + datetime.timedelta(days=days) for days in range(1, diff)]\n",
    "\n",
    "get_next_dates_udf = udf(_get_next_dates, ArrayType(DateType()))\n",
    "\n",
    "window = Window.orderBy(*[], \"jobStartDate\")\n",
    "df3 = df1.withColumn(\"_diff\", datediff(lead(\"jobStartDate\", 1).over(window), \"jobStartDate\"))\n",
    " \n",
    "df2 = df1.withColumn(\"_diff\", datediff(lead(\"jobStartDate\", 1).over(window), \"jobStartDate\")) \\\n",
    "    .filter(col(\"_diff\") > 1) \\\n",
    "    .withColumn(\"_next_dates\", get_next_dates_udf(\"jobStartDate\", \"_diff\")) \\\n",
    "   .withColumn(\"salary\", lit(\"0\")).withColumn(\"jobStartDate\", explode(\"_next_dates\")) \\\n",
    "   .drop(\"_diff\", \"_next_dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|jobStartDate|salary|\n",
      "+------------+------+\n",
      "|  2006-01-03|     0|\n",
      "|  2006-01-06|     0|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-----+\n",
      "|jobStartDate|salary|_diff|\n",
      "+------------+------+-----+\n",
      "|  2006-01-01|     1|    1|\n",
      "|  2006-01-02|     2|    2|\n",
      "|  2006-01-04|     3|    1|\n",
      "|  2006-01-05|     4|    2|\n",
      "|  2006-01-07|     5| null|\n",
      "+------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0012cd877e37c553ce082c8a53dbb8150686811a71a997c633aba52086b562f8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pyspark3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
