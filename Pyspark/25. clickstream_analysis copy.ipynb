{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/54662219/spark-advanced-window-with-dynamic-last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Given a time series data which is a clickstream of user activity is stored in hive, ask is to enrich the data with session id using spark.\n",
    "\n",
    "Session Definition\n",
    "\n",
    "    Session expires after inactivity of 1 hour\n",
    "    Session remains active for a total duration of 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime,col, lit, udf, datediff, lead, explode,to_date\n",
    "from pyspark.sql import SparkSession,Window,DataFrame\n",
    "import datetime\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,LongType,ArrayType\n",
    "from typing import List\n",
    "import pyspark.sql.functions as f\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "streaming_data=[(\"U1\",\"2019-01-01T11:00:00Z\") , \n",
    "(\"U1\",\"2019-01-01T11:15:00Z\") , \n",
    "(\"U1\",\"2019-01-01T12:00:00Z\") , \n",
    "(\"U1\",\"2019-01-01T12:20:00Z\") , \n",
    "(\"U1\",\"2019-01-01T15:00:00Z\") , \n",
    "(\"U2\",\"2019-01-01T11:00:00Z\") , \n",
    "(\"U2\",\"2019-01-02T11:00:00Z\") , \n",
    "(\"U2\",\"2019-01-02T11:25:00Z\") , \n",
    "(\"U2\",\"2019-01-02T11:50:00Z\") , \n",
    "(\"U2\",\"2019-01-02T12:15:00Z\") , \n",
    "(\"U2\",\"2019-01-02T12:40:00Z\") , \n",
    "(\"U2\",\"2019-01-02T13:05:00Z\") , \n",
    "(\"U2\",\"2019-01-02T13:20:00Z\") ]\n",
    "schema=(\"UserId\",\"Click_Time\")\n",
    "df_stream=spark.createDataFrame(streaming_data,schema)\n",
    "df_stream=df_stream.withColumn(\"Click_Time\",df_stream[\"Click_Time\"].cast(\"timestamp\"))\n",
    "df_stream1=df_stream.withColumn(\"Click_Time\",f.unix_timestamp(\"Click_Time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|UserId|         Click_Time|\n",
      "+------+-------------------+\n",
      "|    U1|2019-01-01 16:30:00|\n",
      "|    U1|2019-01-01 16:45:00|\n",
      "|    U1|2019-01-01 17:30:00|\n",
      "|    U1|2019-01-01 17:50:00|\n",
      "|    U1|2019-01-01 20:30:00|\n",
      "|    U2|2019-01-01 16:30:00|\n",
      "|    U2|2019-01-02 16:30:00|\n",
      "|    U2|2019-01-02 16:55:00|\n",
      "|    U2|2019-01-02 17:20:00|\n",
      "|    U2|2019-01-02 17:45:00|\n",
      "|    U2|2019-01-02 18:10:00|\n",
      "|    U2|2019-01-02 18:35:00|\n",
      "|    U2|2019-01-02 18:50:00|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|UserId|Click_Time|\n",
      "+------+----------+\n",
      "|    U1|1546340400|\n",
      "|    U1|1546341300|\n",
      "|    U1|1546344000|\n",
      "|    U1|1546345200|\n",
      "|    U1|1546354800|\n",
      "|    U2|1546340400|\n",
      "|    U2|1546426800|\n",
      "|    U2|1546428300|\n",
      "|    U2|1546429800|\n",
      "|    U2|1546431300|\n",
      "|    U2|1546432800|\n",
      "|    U2|1546434300|\n",
      "|    U2|1546435200|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stream1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------+-----+------------+\n",
      "|UserId|         Click_Time|         time_diff|cond_|temp_session|\n",
      "+------+-------------------+------------------+-----+------------+\n",
      "|    U2|2019-01-01 16:30:00|               0.0|    0|           0|\n",
      "|    U2|2019-01-02 16:30:00|              24.0|    1|           1|\n",
      "|    U2|2019-01-02 16:55:00|0.4166666666666667|    0|           1|\n",
      "|    U2|2019-01-02 17:20:00|0.4166666666666667|    0|           1|\n",
      "|    U2|2019-01-02 17:45:00|0.4166666666666667|    0|           1|\n",
      "|    U2|2019-01-02 18:10:00|0.4166666666666667|    0|           1|\n",
      "|    U2|2019-01-02 18:35:00|0.4166666666666667|    0|           1|\n",
      "|    U2|2019-01-02 18:50:00|              0.25|    0|           1|\n",
      "|    U1|2019-01-01 16:30:00|               0.0|    0|           0|\n",
      "|    U1|2019-01-01 16:45:00|              0.25|    0|           0|\n",
      "|    U1|2019-01-01 17:30:00|              0.75|    0|           0|\n",
      "|    U1|2019-01-01 17:50:00|0.3333333333333333|    0|           0|\n",
      "|    U1|2019-01-01 20:30:00|2.6666666666666665|    1|           1|\n",
      "+------+-------------------+------------------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec=Window.partitionBy(\"UserId\").orderBy(\"Click_Time\")\n",
    "df_stream=df_stream\\\n",
    ".withColumn(\"time_diff\",\n",
    "            (f.unix_timestamp(\"Click_Time\")-f.unix_timestamp(f.lag(f.col(\"Click_Time\"),1).over(window_spec)))/(60*60)).na.fill(0)\n",
    "\n",
    "df_stream=df_stream.withColumn(\"cond_\",f.when(f.col(\"time_diff\")>1,1).otherwise(0))\n",
    "df_stream=df_stream.withColumn(\"temp_session\",f.sum(f.col(\"cond_\")).over(window_spec))\n",
    "df_stream.show(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------+-----+------------+-------------+----------------+\n",
      "|UserId|         Click_Time|         time_diff|cond_|temp_session|2hr_time_diff|temp_session_2hr|\n",
      "+------+-------------------+------------------+-----+------------+-------------+----------------+\n",
      "|    U2|2019-01-01 16:30:00|               0.0|    0|           0|            0|               0|\n",
      "|    U2|2019-01-02 16:30:00|              24.0|    1|           1|            0|               0|\n",
      "|    U2|2019-01-02 16:55:00|0.4166666666666667|    0|           1|         1500|               0|\n",
      "|    U2|2019-01-02 17:20:00|0.4166666666666667|    0|           1|         1500|               0|\n",
      "|    U2|2019-01-02 17:45:00|0.4166666666666667|    0|           1|         1500|               0|\n",
      "|    U2|2019-01-02 18:10:00|0.4166666666666667|    0|           1|         1500|               0|\n",
      "|    U2|2019-01-02 18:35:00|0.4166666666666667|    0|           1|         1500|               1|\n",
      "|    U2|2019-01-02 18:50:00|              0.25|    0|           1|          900|               1|\n",
      "|    U1|2019-01-01 16:30:00|               0.0|    0|           0|            0|               0|\n",
      "|    U1|2019-01-01 16:45:00|              0.25|    0|           0|          900|               0|\n",
      "|    U1|2019-01-01 17:30:00|              0.75|    0|           0|         2700|               0|\n",
      "|    U1|2019-01-01 17:50:00|0.3333333333333333|    0|           0|         1200|               0|\n",
      "|    U1|2019-01-01 20:30:00|2.6666666666666665|    1|           1|            0|               0|\n",
      "+------+-------------------+------------------+-----+------------+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_window=Window.partitionBy(\"UserId\",\"temp_session\").orderBy(\"Click_Time\")\n",
    "new_spec=new_window.rowsBetween(Window.unboundedPreceding,Window.currentRow)\n",
    "cond_2hr=(f.unix_timestamp(\"Click_Time\")-f.unix_timestamp(f.lag(f.col(\"Click_Time\"),1).over(new_window)))\n",
    "df_stream=df_stream.withColumn(\"2hr_time_diff\", cond_2hr).na.fill(0)\n",
    "df_stream=df_stream.withColumn(\"temp_session_2hr\",f.when(f.sum(f.col(\"2hr_time_diff\")).over(new_spec)-(2*60*60)>0,1).otherwise(0))\n",
    "df_stream.show(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------+-----+------------+-------------+----------------+--------------------+\n",
      "|UserId|         Click_Time|         time_diff|cond_|temp_session|2hr_time_diff|temp_session_2hr|final_session_groups|\n",
      "+------+-------------------+------------------+-----+------------+-------------+----------------+--------------------+\n",
      "|    U2|2019-01-01 16:30:00|               0.0|    0|           0|            0|               0|                   0|\n",
      "|    U2|2019-01-02 16:30:00|              24.0|    1|           1|            0|               0|                   0|\n",
      "|    U2|2019-01-02 16:55:00|0.4166666666666667|    0|           1|         1500|               0|                   0|\n",
      "|    U2|2019-01-02 17:20:00|0.4166666666666667|    0|           1|         1500|               0|                   0|\n",
      "|    U2|2019-01-02 17:45:00|0.4166666666666667|    0|           1|         1500|               0|                   0|\n",
      "|    U2|2019-01-02 18:10:00|0.4166666666666667|    0|           1|         1500|               0|                   0|\n",
      "|    U2|2019-01-02 18:35:00|0.4166666666666667|    0|           1|         1500|               1|                   0|\n",
      "|    U2|2019-01-02 18:50:00|              0.25|    0|           1|          900|               1|                   0|\n",
      "|    U1|2019-01-01 16:30:00|               0.0|    0|           0|            0|               0|                   0|\n",
      "|    U1|2019-01-01 16:45:00|              0.25|    0|           0|          900|               0|                   0|\n",
      "|    U1|2019-01-01 17:30:00|              0.75|    0|           0|         2700|               0|                   0|\n",
      "|    U1|2019-01-01 17:50:00|0.3333333333333333|    0|           0|         1200|               0|                   0|\n",
      "|    U1|2019-01-01 20:30:00|2.6666666666666665|    1|           1|            0|               0|                   0|\n",
      "+------+-------------------+------------------+-----+------------+-------------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_window_2hr=Window.partitionBy([\"UserId\",\"temp_session\",\"temp_session_2hr\"]).orderBy(\"Click_Time\")\n",
    "hrs_cond_=(f.when(f.unix_timestamp(f.col(\"Click_Time\"))-f.unix_timestamp(f.first(f.col(\"Click_Time\")).over(new_window_2hr))-(2*60*60)>0,1).otherwise(0))\n",
    "df_stream=df_stream.withColumn(\"final_session_groups\",hrs_cond_)\n",
    "df_stream.show(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----+-------------+-------------+----------+\n",
      "|UserId|Click_Time         |cond_|2hr_time_diff|final_session|session_id|\n",
      "+------+-------------------+-----+-------------+-------------+----------+\n",
      "|U2    |2019-01-01 16:30:00|0    |0            |1            |U21       |\n",
      "|U2    |2019-01-02 16:30:00|1    |0            |2            |U22       |\n",
      "|U2    |2019-01-02 16:55:00|0    |1500         |2            |U22       |\n",
      "|U2    |2019-01-02 17:20:00|0    |1500         |2            |U22       |\n",
      "|U2    |2019-01-02 17:45:00|0    |1500         |2            |U22       |\n",
      "|U2    |2019-01-02 18:10:00|0    |1500         |2            |U22       |\n",
      "|U2    |2019-01-02 18:35:00|0    |1500         |3            |U23       |\n",
      "|U2    |2019-01-02 18:50:00|0    |900          |3            |U23       |\n",
      "|U1    |2019-01-01 16:30:00|0    |0            |1            |U11       |\n",
      "|U1    |2019-01-01 16:45:00|0    |900          |1            |U11       |\n",
      "|U1    |2019-01-01 17:30:00|0    |2700         |1            |U11       |\n",
      "|U1    |2019-01-01 17:50:00|0    |1200         |1            |U11       |\n",
      "|U1    |2019-01-01 20:30:00|1    |0            |2            |U12       |\n",
      "+------+-------------------+-----+-------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stream=df_stream.withColumn(\"final_session\",df_stream[\"temp_session_2hr\"]+df_stream[\"temp_session\"]+df_stream[\"final_session_groups\"]+1)\\\n",
    ".drop(\"temp_session\",\"final_session_groups\",\"time_diff\",\"temp_session_2hr\",\"final_session_groups\")\n",
    "df_stream=df_stream.withColumn(\"session_id\",f.concat(f.col(\"UserId\"),f.col(\"final_session\")))\n",
    "df_stream.show(20,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0012cd877e37c553ce082c8a53dbb8150686811a71a997c633aba52086b562f8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pyspark3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
