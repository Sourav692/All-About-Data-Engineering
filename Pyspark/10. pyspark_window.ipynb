{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Links:\n",
    "\n",
    "    https://medium.com/@sergey.ivanchuk/practical-pyspark-window-function-examples-cb5c7e1a3c41\n",
    "    https://www.educba.com/pyspark-window-functions/\n",
    "    https://knockdata.github.io/spark-window-function/\n",
    "    https://sparkbyexamples.com/pyspark/pyspark-window-functions/\n",
    "    https://www.geeksforgeeks.org/pyspark-window-functions/\n",
    "    https://towardsdatascience.com/spark-sql-102-aggregations-and-window-functions-9f829eaa7549\n",
    "    https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html\n",
    "    https://medium.com/analytics-vidhya/solving-complex-big-data-problems-using-combinations-of-window-functions-deep-dive-in-pyspark-b1830eb00b7d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime,col, lit, udf, datediff, lead, explode,to_date\n",
    "from pyspark.sql import SparkSession,Window,DataFrame\n",
    "import datetime\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,LongType,ArrayType\n",
    "from typing import List\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_data = \\\n",
    "[('Alex','2018-10-10','Paint',80),('Alex','2018-04-02','Ladder',20),('Alex','2018-06-22','Stool',20),\\\n",
    "('Alex','2018-12-09','Vacuum',40),('Alex','2018-07-12','Bucket',5),('Alex','2018-02-18','Gloves',5),\\\n",
    "('Alex','2018-03-03','Brushes',30),('Alex','2018-09-26','Sandpaper',10)]\n",
    "\n",
    "df = spark.createDataFrame(shopping_data, ['name','date','product','price'])\\\n",
    "                .withColumn('date',F.col('date').cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, date: date, product: string, price: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"product\") == \"Paint\").orderBy(col(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- price: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+\n",
      "|name|      date|  product|price|\n",
      "+----+----------+---------+-----+\n",
      "|Alex|2018-10-10|    Paint|   80|\n",
      "|Alex|2018-04-02|   Ladder|   20|\n",
      "|Alex|2018-06-22|    Stool|   20|\n",
      "|Alex|2018-12-09|   Vacuum|   40|\n",
      "|Alex|2018-07-12|   Bucket|    5|\n",
      "|Alex|2018-02-18|   Gloves|    5|\n",
      "|Alex|2018-03-03|  Brushes|   30|\n",
      "|Alex|2018-09-26|Sandpaper|   10|\n",
      "+----+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------+\n",
      "|name|      date|  product|price|price_rank|\n",
      "+----+----------+---------+-----+----------+\n",
      "|Alex|2018-10-10|    Paint|   80|         1|\n",
      "|Alex|2018-12-09|   Vacuum|   40|         2|\n",
      "|Alex|2018-03-03|  Brushes|   30|         3|\n",
      "|Alex|2018-04-02|   Ladder|   20|         4|\n",
      "|Alex|2018-06-22|    Stool|   20|         4|\n",
      "|Alex|2018-09-26|Sandpaper|   10|         5|\n",
      "|Alex|2018-07-12|   Bucket|    5|         6|\n",
      "|Alex|2018-02-18|   Gloves|    5|         6|\n",
      "+----+----------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w0 = Window.partitionBy('name')\n",
    "\n",
    "# Sort purchases by descending order of price and have continuous ranking for ties.\n",
    "\n",
    "df.withColumn(\"price_rank\",F.dense_rank().over(w0.orderBy(F.col('price').desc()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------+\n",
      "|name|      date|  product|price|price_rank|\n",
      "+----+----------+---------+-----+----------+\n",
      "|Alex|2018-10-10|    Paint|   80|         1|\n",
      "|Alex|2018-12-09|   Vacuum|   40|         2|\n",
      "|Alex|2018-03-03|  Brushes|   30|         3|\n",
      "|Alex|2018-04-02|   Ladder|   20|         4|\n",
      "|Alex|2018-06-22|    Stool|   20|         4|\n",
      "|Alex|2018-09-26|Sandpaper|   10|         5|\n",
      "|Alex|2018-07-12|   Bucket|    5|         6|\n",
      "|Alex|2018-02-18|   Gloves|    5|         6|\n",
      "+----+----------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1= Window.partitionBy('name').orderBy(F.col('price').desc())\n",
    "\n",
    "df.withColumn(\"price_rank\",F.dense_rank().over(w1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------+\n",
      "|name|      date|  product|price|price_rank|\n",
      "+----+----------+---------+-----+----------+\n",
      "|Alex|2018-07-12|   Bucket|    5|         1|\n",
      "|Alex|2018-02-18|   Gloves|    5|         1|\n",
      "|Alex|2018-09-26|Sandpaper|   10|         3|\n",
      "|Alex|2018-04-02|   Ladder|   20|         4|\n",
      "|Alex|2018-06-22|    Stool|   20|         4|\n",
      "|Alex|2018-03-03|  Brushes|   30|         6|\n",
      "|Alex|2018-12-09|   Vacuum|   40|         7|\n",
      "|Alex|2018-10-10|    Paint|   80|         8|\n",
      "+----+----------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort purchases by ascending order of price and have skip rankings for ties.\n",
    "df.withColumn(\"price_rank\",F.rank().over(w0.orderBy(F.col('price').asc()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------+\n",
      "|name|      date|  product|price|price_rank|\n",
      "+----+----------+---------+-----+----------+\n",
      "|Alex|2018-10-10|    Paint|   80|         1|\n",
      "|Alex|2018-12-09|   Vacuum|   40|         1|\n",
      "|Alex|2018-03-03|  Brushes|   30|         2|\n",
      "|Alex|2018-04-02|   Ladder|   20|         2|\n",
      "|Alex|2018-06-22|    Stool|   20|         3|\n",
      "|Alex|2018-09-26|Sandpaper|   10|         3|\n",
      "|Alex|2018-07-12|   Bucket|    5|         4|\n",
      "|Alex|2018-02-18|   Gloves|    5|         4|\n",
      "+----+----------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bucket purchases into 4 tiles (e.g. least expensive, middle tiers and most expensive purchases). and sort descending order of price\n",
    "df.withColumn(\"price_rank\",F.ntile(4).over(w0.orderBy(F.col('price').desc()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+-------------------+\n",
      "|name|      date|  product|price|     price_rel_rank|\n",
      "+----+----------+---------+-----+-------------------+\n",
      "|Alex|2018-10-10|    Paint|   80|                0.0|\n",
      "|Alex|2018-12-09|   Vacuum|   40|0.14285714285714285|\n",
      "|Alex|2018-03-03|  Brushes|   30| 0.2857142857142857|\n",
      "|Alex|2018-04-02|   Ladder|   20|0.42857142857142855|\n",
      "|Alex|2018-06-22|    Stool|   20|0.42857142857142855|\n",
      "|Alex|2018-09-26|Sandpaper|   10| 0.7142857142857143|\n",
      "|Alex|2018-07-12|   Bucket|    5| 0.8571428571428571|\n",
      "|Alex|2018-02-18|   Gloves|    5| 0.8571428571428571|\n",
      "+----+----------+---------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort purchases and generating a relative/percent rank to distance from max price.\n",
    "df.withColumn('price_rel_rank',F.percent_rank().over(w0.orderBy(F.col('price').desc()))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row Item Difference - Lead and Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    The two functions below, lag and lead, are probably the most abstract examples in this article and could be confusing at first. \\n    The core concept here is essentially a subtraction between some row (e.g. current) and prior or future row(s). \\n    For examples, from the table below we can say “ 13 = (2018–03–03) — (2018–02–18) “ — which is a difference of days between two dates.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    The two functions below, lag and lead, are probably the most abstract examples in this article and could be confusing at first. \n",
    "    The core concept here is essentially a subtraction between some row (e.g. current) and prior or future row(s). \n",
    "    For examples, from the table below we can say “ 13 = (2018–03–03) — (2018–02–18) “ — which is a difference of days between two dates.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+-----------------------+-------------------------+\n",
      "|name|      date|  product|price|days_from_last_purchase|days_before_next_purchase|\n",
      "+----+----------+---------+-----+-----------------------+-------------------------+\n",
      "|Alex|2018-02-18|   Gloves|    5|                   null|                       13|\n",
      "|Alex|2018-03-03|  Brushes|   30|                     13|                       30|\n",
      "|Alex|2018-04-02|   Ladder|   20|                     30|                       81|\n",
      "|Alex|2018-06-22|    Stool|   20|                     81|                       20|\n",
      "|Alex|2018-07-12|   Bucket|    5|                     20|                       76|\n",
      "|Alex|2018-09-26|Sandpaper|   10|                     76|                       14|\n",
      "|Alex|2018-10-10|    Paint|   80|                     14|                       60|\n",
      "|Alex|2018-12-09|   Vacuum|   40|                     60|                     null|\n",
      "+----+----------+---------+-----+-----------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('days_from_last_purchase', F.datediff('date',F.lag('date',1).over(w0.orderBy(F.col('date')))))\\\n",
    "  .withColumn('days_before_next_purchase', F.datediff(F.lead('date',1).over(w0.orderBy(F.col('date'))),'date'))\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will give error as over not there\n",
    "# df.withColumn('days_from_last_purchase', F.datediff('date',F.lag('date',1)))\\\n",
    "#   .withColumn('days_before_next_purchase', F.datediff(F.lead('date',1),'date'))\\\n",
    "#   .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations : Lists and Sets\n",
    "\n",
    "    Collect a set of prices ever paid (no duplicates) and collect a list of items paid at a certain price (permit duplicates).\n",
    "\n",
    "    I’m adding another purchase of paint to my data set in line 1 for the sake of example to generate duplicated items in lines 14 & 15 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------------+--------------------+\n",
      "|name|      date|  product|price|  items_by_price|          all_prices|\n",
      "+----+----------+---------+-----+----------------+--------------------+\n",
      "|Alex|2018-07-12|   Bucket|    5|[Bucket, Gloves]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-02-18|   Gloves|    5|[Bucket, Gloves]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-09-26|Sandpaper|   10|     [Sandpaper]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-10-10|    Paint|   80|  [Paint, Paint]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-10-11|    Paint|   80|  [Paint, Paint]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-03-03|  Brushes|   30|       [Brushes]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-04-02|   Ladder|   20| [Ladder, Stool]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-06-22|    Stool|   20| [Ladder, Stool]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-12-09|   Vacuum|   40|        [Vacuum]|[30, 5, 20, 10, 4...|\n",
      "+----+----------+---------+-----+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newRow = spark.createDataFrame([('Alex','2018-10-11','Paint',80)])\n",
    "df2 = df.union(newRow)\n",
    "\n",
    "df2.withColumn('items_by_price', F.collect_list('product').over(w0.partitionBy('price')))\\\n",
    "   .withColumn('all_prices',     F.collect_set('price').over(w0)).show()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------------+\n",
      "|name|Price|           items|\n",
      "+----+-----+----------------+\n",
      "|Alex|    5|[Bucket, Gloves]|\n",
      "|Alex|   10|     [Sandpaper]|\n",
      "|Alex|   80|         [Paint]|\n",
      "|Alex|   30|       [Brushes]|\n",
      "|Alex|   20| [Ladder, Stool]|\n",
      "|Alex|   40|        [Vacuum]|\n",
      "+----+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn('items', F.collect_set('product').over(w0.partitionBy('price')))\\\n",
    "   .select('name','Price','items')\\\n",
    "   .distinct()\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average, Sum, Max, Max within Rows, Counts\n",
    "    \n",
    "    Below are 5 very common calculations in single operation: avg + round, sum, max, max + rowsBetween ,\n",
    "    and count. They help us understanding various purchasing behavior about a profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+-----------+----------------+-----------+------------+-------------+\n",
      "|name|      date|  product|price|avg_to_date|accumulating_sum|max_to_date|max_of_last2|items_to_date|\n",
      "+----+----------+---------+-----+-----------+----------------+-----------+------------+-------------+\n",
      "|Alex|2018-02-18|   Gloves|    5|        5.0|               5|          5|           5|            1|\n",
      "|Alex|2018-03-03|  Brushes|   30|       17.5|              35|         30|          30|            2|\n",
      "|Alex|2018-04-02|   Ladder|   20|      18.33|              55|         30|          30|            3|\n",
      "|Alex|2018-06-22|    Stool|   20|      18.75|              75|         30|          20|            4|\n",
      "|Alex|2018-07-12|   Bucket|    5|       16.0|              80|         30|          20|            5|\n",
      "|Alex|2018-09-26|Sandpaper|   10|       15.0|              90|         30|          10|            6|\n",
      "|Alex|2018-10-10|    Paint|   80|      24.29|             170|         80|          80|            7|\n",
      "|Alex|2018-12-09|   Vacuum|   40|      26.25|             210|         80|          80|            8|\n",
      "+----+----------+---------+-----+-----------+----------------+-----------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1 = w0.orderBy(F.col('date'))\n",
    "\n",
    "df.withColumn('avg_to_date',     F.round(F.avg('price').over(w1),2))\\\n",
    "  .withColumn('accumulating_sum',F.sum('price').over(w1))\\\n",
    "  .withColumn('max_to_date',     F.max('price').over(w1))\\\n",
    "  .withColumn('max_of_last2',    F.max('price').over(w1.rowsBetween(-1,Window.currentRow)))\\\n",
    "  .withColumn('items_to_date',   F.count('*').over(w1))\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Complex Window Functions Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------+------+------+\n",
      "|function_name|param1|param2|param3|result|\n",
      "+-------------+------+------+------+------+\n",
      "|           f1|     a|     b|     c|     1|\n",
      "|           f1|     b|     d|     m|     0|\n",
      "|           f2|     a|     b|     c|     0|\n",
      "|           f2|     b|     d|     m|     0|\n",
      "|           f3|     a|     b|     c|     1|\n",
      "|           f3|     b|     d|     m|     1|\n",
      "|           f4|     a|     b|     c|     0|\n",
      "|           f4|     b|     d|     m|     0|\n",
      "+-------------+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list=[['f1','a','b','c',1],\n",
    "     ['f1','b','d','m',0],\n",
    "     ['f2','a','b','c',0],\n",
    "     ['f2','b','d','m',0],\n",
    "     ['f3','a','b','c',1],\n",
    "     ['f3','b','d','m',1],\n",
    "     ['f4','a','b','c',0],\n",
    "      ['f4','b','d','m',0]]\n",
    "\n",
    "df= spark.createDataFrame(list,['function_name','param1','param2','param3','result'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Required:\n",
    "\n",
    "result_list |  function_name_lists\n",
    "------------------------------------\n",
    "    [1,0]   |   [f1]\n",
    "    [0,0]   |   [f2,f4]\n",
    "    [1,1]   |   [f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=Window().partitionBy(\"function_name\").orderBy(F.col(\"param1\"),F.col(\"param2\"),F.col(\"param3\"))\n",
    "w1 = Window.partitionBy(\"function_name\")\n",
    "\n",
    "df1 = df.withColumn(\"result_list\",F.collect_list(\"result\").over(w)).withColumn(\"rowNumber\",F.row_number().over(w)).withColumn(\"result3\",F.max(\"rowNumber\").over(w1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------+------+------+-----------+---------+-------+\n",
      "|function_name|param1|param2|param3|result|result_list|rowNumber|result3|\n",
      "+-------------+------+------+------+------+-----------+---------+-------+\n",
      "|           f2|     a|     b|     c|     0|        [0]|        1|      2|\n",
      "|           f2|     b|     d|     m|     0|     [0, 0]|        2|      2|\n",
      "|           f4|     a|     b|     c|     0|        [0]|        1|      2|\n",
      "|           f4|     b|     d|     m|     0|     [0, 0]|        2|      2|\n",
      "|           f1|     a|     b|     c|     1|        [1]|        1|      2|\n",
      "|           f1|     b|     d|     m|     0|     [1, 0]|        2|      2|\n",
      "|           f3|     a|     b|     c|     1|        [1]|        1|      2|\n",
      "|           f3|     b|     d|     m|     1|     [1, 1]|        2|      2|\n",
      "+-------------+------+------+------+------+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|function_name|result_list|\n",
      "+-------------+-----------+\n",
      "|           f2|     [0, 0]|\n",
      "|           f4|     [0, 0]|\n",
      "|           f1|     [1, 0]|\n",
      "|           f3|     [1, 1]|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.filter(col(\"rowNumber\") == col(\"result3\")).drop(\"param1\",\"param2\",\"param3\",\"result\",\"rowNumber\",\"result3\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupBy(\"result_list\").agg(F.collect_list(\"function_name\").alias(\"function_name_list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|result_list|function_name_list|\n",
      "+-----------+------------------+\n",
      "|     [1, 0]|              [f1]|\n",
      "|     [1, 1]|              [f3]|\n",
      "|     [0, 0]|          [f2, f4]|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input:\n",
    "![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/aec861e5-6496-4a0d-878a-0deeff55a0db/Untitled.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output\n",
    "\n",
    "![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/77514104-dccc-4116-99d4-f47db0cd947a/Untitled.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0012cd877e37c553ce082c8a53dbb8150686811a71a997c633aba52086b562f8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pyspark3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
